"""
Задание 2.
Предложите фундаментальные варианты оптимизации памяти
 и доказать (наглядно, кодом, если получится) их эффективность

Например, один из вариантов, использование генераторов
"""

"""
Довольно частая задача при реализации машинного обучения - нормализация входных данных. Набор признаков, описывающих како-либо явление состоит из различных по маштабу и размерности данных.
Например возраст людей это часто число в пределах от 1 до 100
А число детей в семье довольно редко превышает 5 
С другой стороны остаток на банковском счете может измерятся сотями тысяч или миллионами единиц.
Сотнями единиц может измерятся количество просмотренных товаров в интернет магазине за месяц и т.п.
Для того чтобы алгоритм машинного обуечения мог кооректно обработать данные вне зависимости от маштаба применяют различные методы маштабирования данных. Один из наиболее популярных нормалиция - т.е приведение к 0 среднему значению и зничению стандартного отклоения в пределах от -1 до 1. 
Ввиду того, что значительная часть величин являются нормально распределенными, нормализация позволяет использовать на данных статистический инструментаций разработанный на основании закона нормального распределения.
"""

import numpy as np # импорты библиотек для работы с данными
import pandas as pd

from memory_profiler import profile

def make_features(n = 5, m = 10):
    """
    Возвращает объект pandas.DataFrame - набор данных признаков, нормально распределнных
    и разных по масштабу

    """
    rnd = np.random.RandomState(42)
    X = rnd.normal(size = (m,n))

    for i in range(n):  #  отмаштабируем столбцы с данными 
        X[:, i] = X[:, i]* 10**(i+1)

    cols = ['X'+str(i) for i in range(n)] # Наименование колонок

    return pd.DataFrame(X, columns = cols)


def ml_model(data):
    """
    Функция-заглушка, имитирующая передацу данных в модель машинного обуечения
    """
    #print(data)
    return np.sum(np.mean(data))

@profile
def example1(X):
    """

    Получает DataFrame.
    Очевидный метод хранение  маштабированных данных в новой переменной области памяти и путем создания новой переменой
    """
    cnt = X.shape[0] # количество строк в наборе данных
    mean = X.mean() # вектор средних значений по каждому столбцу
    std = X.std() # вектор стандартных отклонений

    X_norm = (X - mean)/std

    # имитируем пакетное обучение модели - передаем данные пакетами  по пять элементов

    for i in range(cnt//5):
        ml_model(X_norm.iloc[i*5: i*5+5,:])


    return

"""Применение генераторов"""
@profile
def example2(X):
    """
    Подготовка данных "на лету" с помощью генератора
    """
    cnt = X.shape[0] # количество строк в наборе данных
    mean = X.mean()
    std = X.std()

    def norm_gen(data, mean, std, m, batch_size = 5):
        """
        Генератор - получает исходный набор данных и возращает нормализованный 
        пакет данных
        """
        k = 0 # управляющая переменная

        while k <= m:
            batch = (data.iloc[k:k+batch_size, :] - mean) / std
            k += batch_size
            yield batch

    gen = norm_gen(X, mean, std, cnt,5)
    for i in range(cnt//5):
        ml_model(next(gen))

    return 
def main():
    """
    Вызов программы
    """        
    X_data = make_features(5, 10000) # сгенерируем набор данных

    example1(X_data)
    example2(X_data)
    return

if __name__ == '__main__':
    main()


"""
В перво случае для создания новой переменно было выделено 0,8 MiB памяти
При использовании генератора дополнительная память не выделялась. Стоит отметить работу
интерпритатор и уборшика мусора - дополнительная память не выделялась для повторного использования значений переменных mean, std, cnt

Подобное использование генераторов рекоментдует автор фреймворка Keras Франсуа Шолле
для обработки и преобразования наборов признаков большой размерности фотографий, текста и тп. В Keras уже включены наборы генераторов для преобразования фото, текста и потокового видео.


ВЫВОД ПРОГРАММЫ:
python3 'Урок 6. Практическое задание/task_2.py'
Filename: Урок 6. Практическое задание/task_2.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
    48     59.3 MiB     59.3 MiB           1   @profile
    49                                         def example1(X):
    50                                             
    51                                         
    52                                             Получает DataFrame.
    53                                             Очевидный метод хранение  маштабированных данных в новой переменной области памяти и путем создания новой переменой
    54                                            
    55     59.3 MiB      0.0 MiB           1       cnt = X.shape[0] # количество строк в наборе данных
    56     59.3 MiB      0.0 MiB           1       mean = X.mean() # вектор средних значений по каждому столбцу
    57     60.2 MiB      0.9 MiB           1       std = X.std() # вектор стандартных отклонений
    58                                         
    59     61.0 MiB      0.8 MiB           1       X_norm = (X - mean)/std
    60                                         
    61                                             # имитируем пакетное обучение модели - передаем данные пакетами  по пять элементов
    62                                         
    63     61.1 MiB      0.0 MiB        2001       for i in range(cnt//5):
    64     61.1 MiB      0.1 MiB        2000           ml_model(X_norm.iloc[i*5: i*5+5,:])
    65                                         
    66                                         
    67     61.1 MiB      0.0 MiB           1       return


Filename: Урок 6. Практическое задание/task_2.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
    70     61.1 MiB     61.1 MiB           1   @profile
    71                                         def example2(X):
    72                                             """
    73                                  """Подготовка данных на лету с помощью генератора"""
    74                                             """
    75     61.1 MiB      0.0 MiB           1       cnt = X.shape[0] # количество строк в наборе данных
    76     61.1 MiB      0.0 MiB           1       mean = X.mean()
    77     61.1 MiB      0.0 MiB           1       std = X.std()
    78                                         
    79     61.1 MiB      0.0 MiB           2       def norm_gen(data, mean, std, m, batch_size = 5):
    80                                                 
    81                                                 Генератор - получает исходный набор данных и возращает нормализованный 
    82                                                 пакет данных
    83                                                
    84     61.1 MiB      0.0 MiB           1           k = 0 # управляющая переменная
    85                                         
    86     61.1 MiB      0.0 MiB        2000           while k <= m:
    87     61.1 MiB      0.0 MiB        2000               batch = (data.iloc[k:k+batch_size, :] - mean) / std
    88     61.1 MiB      0.0 MiB        2000               k += batch_size
    89     61.1 MiB      0.0 MiB        4000               yield batch
    90                                         
    91     61.1 MiB      0.0 MiB           1       gen = norm_gen(X, mean, std, cnt,5)
    92     61.1 MiB      0.0 MiB        2001       for i in range(cnt//5):
    93     61.1 MiB      0.0 MiB        2000           ml_model(next(gen))
    94                                         
    95     61.1 MiB      0.0 MiB           1       return 

 
"""