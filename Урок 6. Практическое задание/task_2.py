"""
Задание 2.
Предложите фундаментальные варианты оптимизации памяти
 и доказать (наглядно, кодом, если получится) их эффективность

Например, один из вариантов, использование генераторов
"""

# я использую 32-бит Python v 3.8
import copy
from memory_profiler import profile
import sys


def show_sizeof(x, level=0):
    print ("\t" * level, x.__class__, sys.getsizeof(x), x)
    if hasattr(x, '__iter__'):
        if hasattr(x, 'items'):
            for xx in x.items():
                show_sizeof(xx, level + 1)
        else:
            for xx in x:
                show_sizeof(xx, level + 1)


show_sizeof(None)
show_sizeof(3)
show_sizeof(2**63)
show_sizeof(102947298469128649161972364837164)
show_sizeof(918659326943756134897561304875610348756384756193485761304875613948576297485698417)
show_sizeof(3.14159265358979323846264338327950288)
"""
примеры взяты из статьи на хабре
в зависимости от типа объекта потребляется разное кол-во памяти. причем в словарях, которые работают быстро, памяти
требуется больше, чем занимают сами данные, порой в два раза. Потому что кроме самих данных, память тратится на саму 
структуру. Поэтому если требуется сэкономить память, не стоит применять те типы объектов, которые занимают больше памяти
и при этом нет в них необходимости. Так же например не стоит применять float, если число целое. В языках СИ подобных
пользователь сам выбирает тип и если число маленькое, можно примненить int_8, если число положительное, 
то uint (unsigned).
Так же следует удалять элементы если они не используются. del удаляет только список ссылок, поэтому освобождение памяти
хоть и есть, но не значительное.
"""


@profile
def function():
    x = list(range(1000000))  # allocate a big list
    y = copy.deepcopy(x)
    del x
    return y


if __name__ == "__main__":
    function()